{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "469380ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard mathematics and plotting libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For random sampling during network matrix generation\n",
    "from numpy.random import default_rng\n",
    "\n",
    "# For diff. eq. solving via Runge-Kutta 4\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# For activities random sampling according to own power law probability density\n",
    "from scipy.stats import rv_continuous\n",
    "\n",
    "# For execution time measurements\n",
    "import time\n",
    "\n",
    "# For progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4c4d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes\n",
    "class Agent:\n",
    "    def __init__(self, opinion, activity):\n",
    "        self.x=opinion\n",
    "        self.a=activity\n",
    "        \n",
    "    def setOpinion(self, opinion):\n",
    "        self.x=opinion   \n",
    "        \n",
    "    def getOpinion(self):\n",
    "        return self.x\n",
    "    \n",
    "    def setActivity(self, activity):\n",
    "        self.a=activity\n",
    "    \n",
    "    def getActivity(self):\n",
    "        return self.a\n",
    "        \n",
    "class Model:\n",
    "    def __init__(self, N):\n",
    "        \n",
    "        x = np.linspace(-1,1,N)\n",
    "        PowerDistribution = PowerLaw(a=epsilon)\n",
    "        a = PowerDistribution.rvs(size=N)\n",
    "        self.network = []\n",
    "        for i in range(N):\n",
    "            self.network.append(Agent(x[i], a[i]))\n",
    "            \n",
    "    def getNetwork(self):\n",
    "        return self.network\n",
    "    \n",
    "    def getAllOpinions(self):\n",
    "        allOpinions = np.zeros(len(self.network))\n",
    "        for i in range(len(self.network)):\n",
    "            allOpinions[i] = self.network[i].getOpinion()\n",
    "        return allOpinions\n",
    "    \n",
    "    def getAllActivities(self):\n",
    "        allActivities = np.zeros(len(self.network))\n",
    "        for i in range(len(self.network)):\n",
    "            allActivities[i] = self.network[i].getActivity()\n",
    "        return allActivities\n",
    "    \n",
    "    def updateAllOpinions(self, newOpinions):\n",
    "        if len(self.network) == len(newOpinions):\n",
    "            for i in range(len(self.network)):\n",
    "                self.network[i].setOpinion(newOpinions[i])\n",
    "\n",
    "class PowerLaw(rv_continuous):\n",
    "    \"\"\"Activitiy sampling distribution identical to Baumann et al.\n",
    "    It models the intuitive assumption, that by far most people\n",
    "    are hardly posting on social media, and even less people being\n",
    "    very active. \n",
    "    \n",
    "\n",
    "    For Reference, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html#scipy.stats.rv_continuous\"\"\"\n",
    "    \n",
    "    # define probability distribution as the paper's \"F(a)\"\n",
    "    def _pdf(self, x):\n",
    "        return ((1-gamma)/(1-epsilon**(1-gamma)))*x**(-1*gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d5fb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define methods\n",
    "\n",
    "# Implement differential eq. 'dx/dt = [...]' as 'f(t) = [...]' \n",
    "def diffEq(x, t, alpha, K):\n",
    "    sol = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        sum_tmp = 0\n",
    "        for j in range(N):\n",
    "            sum_tmp = sum_tmp+A[i][j]*np.tanh(alpha*x[j])\n",
    "        sol[i] = -x[i]+K*sum_tmp\n",
    "    return sol\n",
    "\n",
    "def calculateProbabilities(i, j, x, beta):\n",
    "    sum_tmp = 0\n",
    "    for j_tmp in range(len(x)):\n",
    "        if x[i] != x[j_tmp]:\n",
    "            sum_tmp = sum_tmp+abs(x[i]-x[j_tmp])**(-beta)\n",
    "    return (abs(x[i]-x[j])**(-beta))/sum_tmp\n",
    "\n",
    "def generateContactMatrix(x, a, beta, m, r):\n",
    "    \n",
    "    # Initialise uniform random number generator [0,1[\n",
    "    # and create to-be-filled matrix A\n",
    "    rng = default_rng()\n",
    "    A = np.zeros((N,N))\n",
    "    \n",
    "    # Iterate through every agent\n",
    "    for i in range(N):\n",
    "        \n",
    "        #Test, if agent is activated\n",
    "        if a[i] > rng.random():\n",
    "        \n",
    "            # If activated, calculate each probability p_ij and sample contacted agents\n",
    "            for j in range(N):\n",
    "                if i != j:\n",
    "                    A[j][i] = calculateProbabilities(i, j, x, beta)\n",
    "                    if m*A[j][i] > rng.random():\n",
    "                        A[j][i] = 1\n",
    "\n",
    "                        # Introduce reciprocal contacting, occuring with probability r:\n",
    "                        if r > rng.random():\n",
    "                            A[i][j] = 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2c57087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fixed parameters\n",
    "t_current = 0\n",
    "tMax = 10\n",
    "dt = 0.01\n",
    "N = 100\n",
    "K=3\n",
    "\n",
    "# Define different alpha, beta values as arrays from which to pick for each graph\n",
    "alphas = np.array([0.05, 3, 3])\n",
    "betas = np.array([2, 0, 3])\n",
    "alpha_current = alphas[0]\n",
    "beta_current = betas[0]\n",
    "\n",
    "# Fixed activity-driving (AD) parameters\n",
    "m = 10\n",
    "epsilon = 0.01\n",
    "gamma = 2.1\n",
    "r = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Model started\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 434/1000 [01:09<01:19,  7.10it/s]"
     ]
    }
   ],
   "source": [
    "# Initialise agents via Model class and get opinions for start of dynamics\n",
    "model = Model(N)\n",
    "opinionStorage = model.getAllOpinions()\n",
    "\n",
    "execution_start_time = time.time()\n",
    "print('---\\nModel started\\n---\\n')\n",
    "\n",
    "# Integrate dynamics with 4th order Runge-Kutta (RK4)\n",
    "for t in tqdm(np.arange(0, tMax, dt)):\n",
    "    \n",
    "    # Update current time\n",
    "    t_current = t + dt\n",
    "    \n",
    "    # Integrate opinion differential equation from t_current-dt to t_current\n",
    "    currentOpinions = model.getAllOpinions()\n",
    "    currentActivites = model.getAllActivities()\n",
    "    t_RK4 = np.linspace(t_current-dt, t_current, 2)\n",
    "    A = generateContactMatrix(currentOpinions, currentActivites, beta_current, m, r)\n",
    "    solODE = odeint(diffEq, currentOpinions, t_RK4, args=(alpha_current, K))\n",
    "\n",
    "    # Update and store new opinions in agents and storage array\n",
    "    newOpinions = solODE[-1]\n",
    "    model.updateAllOpinions(newOpinions)\n",
    "    opinionStorage = np.vstack([opinionStorage, newOpinions])\n",
    "\n",
    "print('\\n---\\nModel finished\\n---')\n",
    "execution_end_time = time.time()\n",
    "print('\\n---\\nTime needed:\\t',execution_end_time-execution_start_time,'\\n---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results:\n",
    "\n",
    "# Globally change font size for Matplotlib plots\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Get time values for plotting out of storage array information\n",
    "time_finish = len(opinionStorage)*dt\n",
    "time_0 = 0\n",
    "times = np.arange(time_0, time_finish, dt)\n",
    "\n",
    "# Plot each agent via looping over storage array\n",
    "for i in range(len(opinionStorage.T)):\n",
    "    \n",
    "    # In case the last value of agent i is negative, the graph color will be changed to red \n",
    "    if opinionStorage.T[i][-1] < 0:\n",
    "        color = 'r'\n",
    "    else:\n",
    "        color ='b'   \n",
    "    plt.plot(times, opinionStorage.T[i], color, linewidth=.25)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Opinion')\n",
    "plt.title('Agent-based activity-driven opinion dynamics', size=16.5)\n",
    "plt.grid()\n",
    "plt.xlim([0,10])\n",
    "#plt.ylim([-1, 1])\n",
    "#plt.xticks([0, 5, 10])\n",
    "#plt.yticks([-5, 0, 5])\n",
    "\n",
    "# Uncomment if you do want to save the figure:\n",
    "file_name = 'Dynamics--N='+str(N)+'--alpha='+str(alpha_current)+'--beta='+str(beta_current)\n",
    "np.savetxt(str(file_name+'.txt'), opinionStorage.T)\n",
    "plt.savefig(str(file_name+'.png'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ab2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following includes the whole script routine,\n",
    "# working over every value of the \"alphas\", \"betas\" arrays\n",
    "# and saving each graph.\n",
    "\n",
    "# Define fixed parameters\n",
    "t_current = 0\n",
    "tMax = 10\n",
    "dt = 0.01\n",
    "N = 100\n",
    "K=3\n",
    "\n",
    "# Define different alpha, beta values as arrays from which to pick for each graph\n",
    "alphas = np.array([0.05, 3, 3])\n",
    "betas = np.array([2, 0, 3])\n",
    "alpha_current = alphas[0]\n",
    "beta_current = betas[0]\n",
    "\n",
    "# Fixed activity-driving (AD) parameters\n",
    "m = 10\n",
    "epsilon = 0.01\n",
    "gamma = 2.1\n",
    "r = 0.5\n",
    "\n",
    "\n",
    "# Initialise and run model in the following:\n",
    "for i in range(len(alphas)):\n",
    "    \n",
    "    # Set current time to start time 0, set alpha and beta parameters\n",
    "    t_current = 0\n",
    "    alpha_current = alphas[i]\n",
    "    beta_current = betas[i]\n",
    "    \n",
    "    # Initialise agents via Model class and get opinions for start of dynamics\n",
    "    model = Model(N)\n",
    "    opinionStorage = model.getAllOpinions()\n",
    "\n",
    "    execution_start_time = time.time()\n",
    "    print('---\\nModel started\\n---\\n')\n",
    "\n",
    "    # Integrate dynamics with 4th order Runge-Kutta (RK4)\n",
    "    for t in tqdm(np.arange(0, tMax, dt)):\n",
    "        \n",
    "        # Update current time\n",
    "        t_current = t + dt\n",
    "        \n",
    "        # Integrate opinion differential equation from t_current-dt to t_current\n",
    "        currentOpinions = model.getAllOpinions()\n",
    "        t_RK4 = np.linspace(t_current-dt, t_current, 2)\n",
    "        A = generateContactMatrix(currentOpinions, beta_current, m, r)\n",
    "        solODE = odeint(diffEq, currentOpinions, t_RK4, args=(alpha_current, K))\n",
    "\n",
    "        # Update and store new opinions in agents and storage array\n",
    "        newOpinions = solODE[-1]\n",
    "        model.updateAllOpinions(newOpinions)\n",
    "        opinionStorage = np.vstack([opinionStorage, newOpinions])\n",
    "\n",
    "    print('\\n---\\nModel finished\\n---')\n",
    "    execution_end_time = time.time()\n",
    "    print('\\n---\\nTime needed:\\t',execution_end_time-execution_start_time,'\\n---')\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the results:\n",
    "\n",
    "    # Globally change font size for Matplotlib plots\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "    # Get time values for plotting out of storage array information\n",
    "    time_finish = len(opinionStorage)*dt\n",
    "    time_0 = 0\n",
    "    times = np.arange(time_0, time_finish, dt)\n",
    "\n",
    "    # Plot each agent via looping over storage array\n",
    "    for i in range(len(opinionStorage.T)):\n",
    "        \n",
    "        # In case the last value of agent i is negative, the graph color will be changed to red \n",
    "        if opinionStorage.T[i][-1] < 0:\n",
    "            color = 'r'\n",
    "        else:\n",
    "            color ='b'   \n",
    "        plt.plot(times, opinionStorage.T[i], color, linewidth=.25)\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Opinion')\n",
    "    plt.title('Agent-based activity-driven opinion dynamics', size=16.5)\n",
    "    plt.grid()\n",
    "    plt.xlim([0,10])\n",
    "    \n",
    "    #plt.ylim([-1, 1])\n",
    "    #plt.xticks([0, 5, 10])\n",
    "    #plt.yticks([-5, 0, 5])\n",
    "\n",
    "    # Uncomment if you do want to save the figure:\n",
    "    file_name = 'Dynamics--N='+str(N)+'--alpha='+str(alpha_current)+'--beta='+str(beta_current)\n",
    "    np.savetxt(str(file_name+'.txt'), opinionStorage.T)\n",
    "    plt.savefig(str(file_name+'.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca153fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
